{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK = 'InceptionResNetV2'\n",
    "# NETWORK = 'InceptionV3'\n",
    "# NETWORK = 'Resnet'\n",
    "# NETWORK = 'VGG16'\n",
    "# NETWORK = 'VGG19'\n",
    "# NETWORK = 'Xception'\n",
    "# NETWORK = 'DenseNet201'\n",
    "# NETWORK = 'EfficientNetB1'\n",
    "# NETWORK = 'EfficientNetB4'\n",
    "# NETWORK = 'EfficientNetB7'\n",
    "# NETWORK = 'NASNetLarge'\n",
    "NETWORK = 'ConvNeXtBase'\n",
    "\n",
    "METHOD = \"AVG-Mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datassd/WHOLEIMAGE_MAMIP/EXTRACTED_FEATURES/ExtractedFeatures_AVG-Mean/Features_ConvNeXtBase_MA-MIP_WHOLE-IMAGE.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/datassd/WHOLEIMAGE_MAMIP/FEATURES_PREPARATION/Feature_Preparation_MA-MIP_AVG-Mean.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a7572655f564d227d/datassd/WHOLEIMAGE_MAMIP/FEATURES_PREPARATION/Feature_Preparation_MA-MIP_AVG-Mean.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m PET_featurs_full_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(features_path, PET_features_filename)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a7572655f564d227d/datassd/WHOLEIMAGE_MAMIP/FEATURES_PREPARATION/Feature_Preparation_MA-MIP_AVG-Mean.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m PET_filename \u001b[39m=\u001b[39m PET_features_filename\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a7572655f564d227d/datassd/WHOLEIMAGE_MAMIP/FEATURES_PREPARATION/Feature_Preparation_MA-MIP_AVG-Mean.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m PET_outcome_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(PET_featurs_full_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22417a7572655f564d227d/datassd/WHOLEIMAGE_MAMIP/FEATURES_PREPARATION/Feature_Preparation_MA-MIP_AVG-Mean.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m outcome_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/datassd/WHOLEIMAGE_MAMIP/hecktor2022_patient_endpoint_training.csv\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/data/anaconda/envs/OP/lib/python3.8/site-packages/pandas/io/parsers.py:688\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    635\u001b[0m     engine_specified \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    637\u001b[0m kwds\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    638\u001b[0m     delimiter\u001b[39m=\u001b[39mdelimiter,\n\u001b[1;32m    639\u001b[0m     engine\u001b[39m=\u001b[39mengine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    685\u001b[0m     skip_blank_lines\u001b[39m=\u001b[39mskip_blank_lines,\n\u001b[1;32m    686\u001b[0m )\n\u001b[0;32m--> 688\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/data/anaconda/envs/OP/lib/python3.8/site-packages/pandas/io/parsers.py:454\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    451\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    453\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(fp_or_buf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    457\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/data/anaconda/envs/OP/lib/python3.8/site-packages/pandas/io/parsers.py:948\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwds:\n\u001b[1;32m    946\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 948\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/data/anaconda/envs/OP/lib/python3.8/site-packages/pandas/io/parsers.py:1180\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_engine\u001b[39m(\u001b[39mself\u001b[39m, engine\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1179\u001b[0m     \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mc\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1180\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m CParserWrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1181\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m         \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/data/anaconda/envs/OP/lib/python3.8/site-packages/pandas/io/parsers.py:2010\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols_dtype \u001b[39m=\u001b[39m _validate_usecols_arg(kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   2008\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols\n\u001b[0;32m-> 2010\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   2011\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m   2013\u001b[0m passed_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:382\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datassd/WHOLEIMAGE_MAMIP/EXTRACTED_FEATURES/ExtractedFeatures_AVG-Mean/Features_ConvNeXtBase_MA-MIP_WHOLE-IMAGE.csv'"
     ]
    }
   ],
   "source": [
    "# /datassd/WHOLEIMAGE_MAMIP/EXTRACTED_FEATURES\n",
    "WORKING_DIRECTORY = '/datassd/WHOLEIMAGE_MAMIP'\n",
    "PET_features_filename = f\"Features_{NETWORK}_MA-MIP_WHOLE-IMAGE.csv\"\n",
    "\n",
    "features_path = os.path.join(WORKING_DIRECTORY, f\"EXTRACTED_FEATURES/ExtractedFeatures_{METHOD}\")\n",
    "processed_features_path = os.path.join(WORKING_DIRECTORY, f\"PROCESSED_FEATURES/ProcessedFeatures_{METHOD}\")\n",
    "if not os.path.exists(processed_features_path):\n",
    "    os.makedirs(processed_features_path)\n",
    "\n",
    "\n",
    "processed_features_filename = f\"Processed_Features_{NETWORK}_MA-MIP_WHOLE-IMAGE.csv\"\n",
    "processed_features_full_filename = os.path.join(processed_features_path, processed_features_filename)\n",
    "\n",
    "PET_featurs_full_path = os.path.join(features_path, PET_features_filename)\n",
    "\n",
    "PET_filename = PET_features_filename.split(\".\")[0]\n",
    "\n",
    "PET_outcome_data = pd.read_csv(PET_featurs_full_path)\n",
    "\n",
    "outcome_file = \"/datassd/WHOLEIMAGE_MAMIP/hecktor2022_patient_endpoint_training.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PET_outcome_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up to here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Outcome csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD = pd.read_csv(outcome_file)\n",
    "OD = OD.iloc[:,:]\n",
    "OD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD = OD.rename(columns={'PatientID': 'Patient_ID'})\n",
    "OD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_column = PET_outcome_data.columns[0]\n",
    "PET_outcome_data = PET_outcome_data.rename(columns={first_column: 'Patient_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD.columns[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PET_outcome_data.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PET_outcome_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges_list = list()\n",
    "# for col in PET_outcome_data.iloc[:, 1:]:\n",
    "#     col_range = PET_outcome_data[col].max() - PET_outcome_data[col].min()\n",
    "#     ranges_list.append(col_range)\n",
    "#     print(f\"Range of column {col}: {col_range}\")\n",
    "# print(f\"maximum range: {max(ranges_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features_df = pd.merge(PET_outcome_data, OD, on=OD.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_features_df.to_csv(processed_features_full_filename, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5af22b15e8cea8d8f7e91a683eb5b3ffc40137cc2e81e9551986b51688e2925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
